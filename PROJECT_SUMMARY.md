# ğŸ¯ Bengali Dialect Transcription Project - Complete Repository

## âœ… Repository Structure Created

This Git repository contains a complete, production-ready Bengali dialect transcription system for BRAC with the following structure:

```
BracV1/
â”œâ”€â”€ README.md                           # Comprehensive project documentation
â”œâ”€â”€ dev-plan.md                         # Development milestones (M1-M4)
â”œâ”€â”€ LICENSE                             # MIT License
â”œâ”€â”€ .gitignore                          # Git ignore patterns
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”‚
â”œâ”€â”€ data/                               # Data collection and preprocessing
â”‚   â”œâ”€â”€ download_datasets.py            # Download OpenSLR, Common Voice, Bengali.AI
â”‚   â”œâ”€â”€ preprocess.py                   # Audio preprocessing pipeline
â”‚   â”œâ”€â”€ augment.py                      # Data augmentation utilities
â”‚   â”œâ”€â”€ manifests/                      # Dataset metadata (auto-generated)
â”‚   â”œâ”€â”€ brac_dialect/                   # BRAC-specific dialect data
â”‚   â””â”€â”€ brac_corrections/               # User corrections for active learning
â”‚
â”œâ”€â”€ train/                              # Model training scripts
â”‚   â”œâ”€â”€ wav2vec2_finetune.py            # Wav2Vec2 fine-tuning
â”‚   â”œâ”€â”€ whisper_finetune.py             # Whisper fine-tuning
â”‚   â”œâ”€â”€ utils.py                        # Training utilities (text normalization, etc.)
â”‚   â””â”€â”€ finetune_config.yaml            # Training configuration
â”‚
â”œâ”€â”€ eval/                               # Model evaluation
â”‚   â””â”€â”€ eval_wer_cer.py                 # WER/CER evaluation with error analysis
â”‚
â”œâ”€â”€ inference/                          # Inference server and deployment
â”‚   â”œâ”€â”€ server.py                       # FastAPI server with REST endpoints
â”‚   â”œâ”€â”€ transliterate.py                # Bengali â†” IPA â†” Latin transliteration
â”‚   â”œâ”€â”€ export_model.sh                 # Model export (TorchScript, ONNX, Whisper.cpp)
â”‚   â”œâ”€â”€ Dockerfile.cpu                  # CPU container
â”‚   â”œâ”€â”€ Dockerfile.gpu                  # GPU container
â”‚   â”œâ”€â”€ docker-compose.cpu.yml          # Docker Compose for CPU
â”‚   â””â”€â”€ docker-compose.gpu.yml          # Docker Compose for GPU
â”‚
â”œâ”€â”€ frontend/                           # React web interface
â”‚   â”œâ”€â”€ README.md                       # Frontend documentation
â”‚   â”œâ”€â”€ package.json                    # NPM dependencies
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ App.jsx                     # Main React component (drag-drop, transcription UI)
â”‚
â”œâ”€â”€ scripts/                            # Deployment scripts
â”‚   â”œâ”€â”€ deploy_frontend.sh              # Deploy to GitHub Pages
â”‚   â””â”€â”€ deploy_server.md                # Server deployment guide (HF, Railway, GCP, AWS)
â”‚
â””â”€â”€ notebooks/                          # Analysis notebooks
    â””â”€â”€ analysis.ipynb                  # Sample inference and error visualization
```

---

## ğŸš€ Quick Start Guide

### 1. Clone and Setup

```bash
# Clone repository
git clone <your-repo-url>
cd BracV1

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Datasets

```bash
cd data
python download_datasets.py --datasets all --output ./raw
```

### 3. Preprocess Data

```bash
python preprocess.py \
  --input_dirs ./raw/openslr_slr53 ./raw/common_voice_bn \
  --output_dir ./processed \
  --speaker_split
```

### 4. Train Model

```bash
cd ../train
python wav2vec2_finetune.py \
  --train_data ../data/processed/train.tsv \
  --valid_data ../data/processed/valid.tsv \
  --output_dir ../models/wav2vec2_bengali
```

### 5. Evaluate

```bash
cd ../eval
python eval_wer_cer.py \
  --model_path ../models/wav2vec2_bengali/checkpoint-best \
  --test_data ../data/processed/test.tsv \
  --detailed_analysis
```

### 6. Start Inference Server

```bash
cd ../inference
docker-compose -f docker-compose.cpu.yml up
```

### 7. Deploy Frontend

```bash
cd ../frontend
npm install
npm run dev  # Development
npm run build  # Production build
```

---

## ğŸ“‹ Key Features Implemented

### âœ… Data Pipeline
- âœ“ Automated dataset downloaders (OpenSLR, Common Voice, Bengali.AI)
- âœ“ Audio preprocessing (16kHz resampling, normalization, silence trimming)
- âœ“ Speaker-level splitting (prevents data leakage)
- âœ“ Data augmentation (speed perturbation, noise injection, volume changes)

### âœ… Training Infrastructure
- âœ“ Wav2Vec2-XLSR-53 fine-tuning script
- âœ“ Whisper fine-tuning script
- âœ“ Mixed precision training (FP16)
- âœ“ Gradient accumulation and checkpointing
- âœ“ W&B logging integration
- âœ“ Early stopping
- âœ“ Bengali text normalization utilities

### âœ… Evaluation & Analysis
- âœ“ WER/CER calculation
- âœ“ Per-dialect error breakdown
- âœ“ Error pattern analysis (substitutions, deletions, insertions)
- âœ“ Number and code-switching error detection
- âœ“ Jupyter notebook for interactive analysis

### âœ… Inference & Deployment
- âœ“ FastAPI REST API with OpenAPI docs
- âœ“ Endpoints: `/transcribe`, `/transcribe/phonetic`, `/health`
- âœ“ Rate limiting (10 req/min)
- âœ“ Audio format validation
- âœ“ Transliteration support (Epitran + Aksharamukha)
- âœ“ Confidence-based fallback mechanism
- âœ“ Docker containers (CPU and GPU)
- âœ“ Model export scripts (TorchScript, ONNX, Whisper.cpp)

### âœ… Frontend
- âœ“ React 18+ with Vite
- âœ“ Tailwind CSS styling with dark mode
- âœ“ Drag & drop file upload
- âœ“ Audio player preview
- âœ“ Real-time transcription
- âœ“ Toggle Bangla/Latin script
- âœ“ Download .txt and .srt
- âœ“ Responsive design
- âœ“ Accessibility (WCAG 2.1)

### âœ… DevOps & Documentation
- âœ“ Comprehensive README with decision rationale
- âœ“ Development plan with 4 milestones
- âœ“ Deployment guides (Hugging Face, Railway, Vercel, GCP, AWS, self-hosted)
- âœ“ Frontend deployment script (GitHub Pages)
- âœ“ Docker Compose files
- âœ“ .gitignore and LICENSE (MIT)

---

## ğŸ“ Decision Rationale

### Why Fine-tuning Over English-Transliteration?

The repository includes detailed rationale in `README.md` explaining why we chose fine-tuning Bengali ASR models over an English-transliteration shortcut:

1. **Phoneme Loss**: Bengali has unique phonemes not in English
2. **Homophone Confusion**: Multiple spellings for similar sounds
3. **Dialect Variations**: Regional pronunciations don't map to English
4. **Compound Characters**: à¦¯à§à¦•à§à¦¤à¦¾à¦•à§à¦·à¦° (conjunct consonants) require Bengali understanding
5. **Code-Switching**: Better handling of Bengali-English mixing

**Our Approach:**
- Primary: Fine-tune XLSR-Wav2Vec2 and Whisper on Bengali data
- Fallback: Transliteration only when confidence < 0.7
- Hybrid: Combine acoustic model with domain-specific language model

---

## ğŸ› ï¸ Technologies Used

**ML/Data:**
- PyTorch, Transformers (Hugging Face)
- Librosa, Soundfile
- Datasets (Hugging Face)
- Epitran, Aksharamukha (transliteration)

**Backend:**
- FastAPI, Uvicorn
- Docker, Docker Compose

**Frontend:**
- React 18, Vite
- Tailwind CSS
- Axios, React Dropzone

**Evaluation:**
- Jiwer (WER/CER)
- Matplotlib, Seaborn (visualization)

---

## ğŸ“Š Development Milestones

### M1: Data Collection + Baseline (Weeks 1-2)
- Download datasets
- Preprocess
- Train baseline Wav2Vec2
- Target: WER < 30%

### M2: BRAC Dialect Integration (Weeks 3-6)
- Collect BRAC dialect data
- Fine-tune on combined datasets
- Detailed evaluation
- Target: WER < 20%

### M3: Inference Server + Frontend (Weeks 7-8)
- FastAPI server
- React frontend
- Docker deployment
- GitHub Pages hosting

### M4: Active Learning (Weeks 9-10 + Ongoing)
- Correction submission system
- Automated retraining
- Monitoring dashboard

---

## ğŸ”„ Active Learning Pipeline

The system supports continuous improvement:

1. Users submit corrections via frontend
2. Corrections stored in `data/brac_corrections/`
3. Weekly/monthly automated retraining
4. Model performance tracking

---

## ğŸ“š Datasets & References

**Datasets:**
- OpenSLR SLR53: https://www.openslr.org/53/
- Mozilla Common Voice (bn): https://commonvoice.mozilla.org/bn
- Bengali.AI: https://bengali.ai/

**Transliteration:**
- Epitran: https://github.com/dmort27/epitran
- Aksharamukha: https://github.com/virtualvinodh/aksharamukha

**Papers:**
- Wav2Vec 2.0 (Baevski et al., 2020)
- Whisper (Radford et al., 2022)

---

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Commit changes
4. Push and create PR

---

## ğŸ“„ License

MIT License - Open source for BRAC and community use.

---

## ğŸ‰ Summary

This repository provides a **complete, production-ready** Bengali dialect transcription system with:

- âœ… End-to-end data pipeline
- âœ… State-of-the-art model training (Wav2Vec2, Whisper)
- âœ… REST API for inference
- âœ… Modern React frontend
- âœ… Multiple deployment options
- âœ… Active learning capabilities
- âœ… Comprehensive documentation

**Ready to deploy and start transcribing!** ğŸš€

---

*Created: October 29, 2025*  
*Author: BRAC Data Science Team*
